{
 "cells": [
  {
   "cell_type": "raw",
   "id": "97901268-8e26-4d81-baae-a4d00011b680",
   "metadata": {},
   "source": [
    "1.What is a parameter?\n",
    "\n",
    "A parameter is a variable defined in the function definition that acts as a placeholder for the value (argument) that will be passed to the function when it is called. Parameters allow functions to accept inputs and perform operations based on those inputs.\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "985db8c6-e461-4996-8a7c-57f8b5471489",
   "metadata": {},
   "source": [
    "2. What is correlation?  \n",
    "What does negative correlation mean?\n",
    "\n",
    "Correlation is a statistical measure that describes the strength and direction of a relationship between two variables. It ranges from -1 to +1.\n",
    "\n",
    "A negative correlation means that as one variable increases, the other variable decreases. In other words, they move in opposite directions. For example, if the temperature goes down, the sales of heaters may go up — this is a negative correlation.\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "4be22daf-0bf3-4a78-9552-de0841a27a42",
   "metadata": {},
   "source": [
    "3.Define Machine Learning. What are the main components in Machine Learning?\n",
    "\n",
    "Machine Learning is a subset of Artificial Intelligence (AI) that enables systems to learn from data, identify patterns, and make decisions with minimal human intervention.\n",
    "\n",
    "The main components in Machine Learning are:\n",
    "1. Data – The input used to train the model.\n",
    "2. Model– The algorithm that learns from the data.\n",
    "3. Training – The process of teaching the model using data.\n",
    "4. Prediction– The outcome or result the model provides based on new input data.\n",
    "5. Evaluation – Assessing the model's performance using metrics.\n",
    "6. Feature Extraction– Selecting and transforming input variables to improve model performance.\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "7efcbcd7-de3c-43fd-a1e6-e7fdc6ae6811",
   "metadata": {},
   "source": [
    "4.How does loss value help in determining whether the model is good or not?\n",
    "\n",
    "The loss value indicates how well or poorly a machine learning model is performing. It measures the difference between the model's predicted values and the actual values.\n",
    "\n",
    "- A low loss value means the model’s predictions are close to the actual values, indicating good performance.\n",
    "- A high loss value means there is a large difference between predictions and actual values, indicating poor performance.\n",
    "\n",
    "Therefore, minimizing the loss value is essential for improving model accuracy and reliability.\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "685099e6-648f-420f-a21b-8836c4001bb5",
   "metadata": {},
   "source": [
    "5.What are continuous and categorical variables?\n",
    "\n",
    "Continuous variablesare numerical variables that can take any value within a range. They are measurable and can have decimal values.\n",
    "  Example: Height, weight, temperature, salary.\n",
    "\n",
    "Categorical variables are variables that represent categories or groups. They are not numerical and cannot be measured, only labeled or classified.\n",
    "  Example: Gender, color, type of car, city name.\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "9342f548-74b0-41d6-a477-11fa2993bfe6",
   "metadata": {},
   "source": [
    "6.How do we handle categorical variables in Machine Learning? What are the common techniques?\n",
    "\n",
    "Categorical variables need to be converted into numerical form before they can be used in machine learning models. Common techniques include:\n",
    "\n",
    "1. Label Encoding – Assigns a unique integer to each category.\n",
    "   Example: {\"Red\": 0, \"Blue\": 1, \"Green\": 2}\n",
    "\n",
    "2. One-Hot Encoding – Creates a new binary column for each category.\n",
    "   Example: \"Red\", \"Blue\", \"Green\" → [1,0,0], [0,1,0], [0,0,1]\n",
    "\n",
    "3. Ordinal Encoding– Similar to label encoding but used when categories have an order.\n",
    "   Example: {\"Low\": 1, \"Medium\": 2, \"High\": 3}\n",
    "\n",
    "Choosing the right method depends on the nature of the categorical variable.\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "9aa1569b-e20d-40e3-824a-bb1165f534e1",
   "metadata": {},
   "source": [
    "7.What do you mean by training and testing a dataset?\n",
    "\n",
    "- Training a dataset means using a portion of the data to teach the machine learning model. The model learns patterns and relationships from this data.\n",
    "\n",
    "- Testing a dataset is used to evaluate the performance of the trained model. It helps to check how well the model can make predictions on new, unseen data.\n",
    "\n",
    "Typically, the dataset is split into:\n",
    "- Training set: Used to train the model (usually 70–80% of the data).\n",
    "- Testing set: Used to test the model’s accuracy and generalization (usually 20–30% of the data).\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "6d54b2b5-de4c-4720-8706-3873cfaad6a7",
   "metadata": {},
   "source": [
    "8.What is sklearn.preprocessing?\n",
    "\n",
    "`sklearn.preprocessing` is a module in the scikit-learn library that provides functions and classes for preprocessing data before feeding it into a machine learning model.\n",
    "\n",
    "Common preprocessing tasks include:\n",
    "- Scaling features (e.g., StandardScaler, MinMaxScaler)\n",
    "- Encoding categorical variables (e.g., LabelEncoder, OneHotEncoder)\n",
    "- Normalization\n",
    "- Binarization\n",
    "\n",
    "Preprocessing helps improve the performance and accuracy of machine learning models.\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "321fef7a-7ea0-4f80-bab5-4f40ec82eb2a",
   "metadata": {},
   "source": [
    "9.What is a Test set?\n",
    "\n",
    "A Test set is a subset of the original dataset that is kept separate from the training data. It is used to evaluate the performance of a trained machine learning model on unseen data to check its generalization ability and accuracy.\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "f234630a-9340-42f3-bb1d-63ee7010aca4",
   "metadata": {},
   "source": [
    "10. How do we split data for model fitting (training and testing) in Python?\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Example: splitting features (X) and labels (y) into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "\n",
    "How do you approach a Machine Learning problem?\n",
    "\n",
    "1. Understand the problem – Define the goal and success criteria.\n",
    "2. Collect data– Gather relevant and sufficient data.\n",
    "3. Explore and preprocess data – Handle missing values, encode categorical variables, normalize or scale features.\n",
    "4. Split the data – Divide into training and testing sets.\n",
    "5. choose a model – Select an appropriate algorithm.\n",
    "6. Train the model – Fit the model to the training data.\n",
    "7. Evaluate the model – Test the model on the test data and analyze performance metrics.\n",
    "8. Tune the model– Optimize hyperparameters to improve performance.\n",
    "9. Deploy the model – Use the model in real-world applications.\n",
    "10.Monitor and maintain– Continuously check the model's performance and update if needed.\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "3c2bd56f-7e7a-4f0c-b5bb-dc8912c423fc",
   "metadata": {},
   "source": [
    "11.Why do we have to perform EDA before fitting a model to the data?\n",
    "\n",
    "Exploratory Data Analysis (EDA) is performed to understand the data’s structure, patterns, and relationships. It helps to:\n",
    "\n",
    "- Detect and handle missing or inconsistent data.\n",
    "- Identify outliers or anomalies.\n",
    "- Understand variable distributions and correlations.\n",
    "- Select relevant features.\n",
    "- Choose appropriate models and preprocessing techniques.\n",
    "\n",
    "Performing EDA ensures better model performance and prevents issues during training.\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "4eccded5-6dcf-44b6-a551-19888e0531ba",
   "metadata": {},
   "source": [
    "12.What is correlation?\n",
    "\n",
    "Correlation is a statistical measure that describes the strength and direction of a linear relationship between two variables. It ranges from -1 to +1:\n",
    "\n",
    "- +1 indicates a perfect positive correlation.\n",
    "- -1 indicates a perfect negative correlation.\n",
    "- 0 indicates no correlation.\n",
    "\n",
    "It helps to understand how one variable changes with respect to another.\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "f8149182-8254-4f02-b9fc-bd3b9232eb4f",
   "metadata": {},
   "source": [
    "13.What does negative correlation mean?\n",
    "\n",
    "Negative correlation means that as one variable increases, the other variable decreases. The two variables move in opposite directions. The correlation coefficient for negative correlation lies between -1 and 0.\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "c531c2e0-5a35-44ea-bf9c-9cc8a82626b0",
   "metadata": {},
   "source": [
    "14. How can you find correlation between variables in Python?\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "Example: calculating correlation matrix of a DataFrame 'df'\n",
    "correlation_matrix = df.corr()\n",
    "\n",
    "print(correlation_matrix)\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "1eddfeb7-46fa-4373-a776-489a6fbdac86",
   "metadata": {},
   "source": [
    "15.What is causation? Explain difference between correlation and causation with an example.\n",
    "\n",
    "Causation means that one event is the direct result of another event happening. It implies a cause-and-effect relationship.\n",
    "\n",
    "Difference between Correlation and Causation:\n",
    "\n",
    "- Correlation means two variables are related or move together, but one does not necessarily cause the other.\n",
    "- Causation means one variable actually causes the change in the other.\n",
    "\n",
    "Example:\n",
    "\n",
    "- Correlation: Ice cream sales and drowning incidents both increase in summer. They are correlated because they both rise at the same time.\n",
    "- Causation: Ice cream sales do NOT cause drowning. The real cause is the hot weather (summer) that increases both ice cream sales and swimming activity (which may lead to drownings).\n",
    "\n",
    "So, correlation does not imply causation.\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "91e23a0a-5a03-49ab-bc91-5e2d4d39156e",
   "metadata": {},
   "source": [
    "16.What is an Optimizer? What are different types of optimizers? Explain each with an example.\n",
    "\n",
    "Optimizer:\n",
    "An optimizer is an algorithm used in machine learning and deep learning to update the model's parameters (weights and biases) to minimize the loss function during training. It controls how the model learns by adjusting parameters to reduce error.\n",
    "\n",
    "Different types of optimizers:\n",
    "\n",
    "1. Gradient Descent (GD):\n",
    "   Updates parameters by moving in the direction of the negative gradient of the loss function. Uses the whole dataset for each update.  \n",
    "   Example:  \n",
    "   θ = θ - learning_rate * gradient\n",
    "\n",
    "2. Stochastic Gradient Descent (SGD): \n",
    "   Updates parameters using the gradient from one data point at a time. Faster but noisier updates.  \n",
    "   Example: Updates after each training sample.\n",
    "\n",
    "3. Mini-batch Gradient Descent: \n",
    "   Combines GD and SGD by updating parameters using small batches of data. Balances speed and stability.\n",
    "\n",
    "4. Momentum: \n",
    "   Accelerates SGD by adding a fraction of the previous update to the current update to smooth convergence.\n",
    "\n",
    "5. Adam (Adaptive Moment Estimation):  \n",
    "   Combines Momentum and RMSProp optimizers, adapts learning rates for each parameter. Widely used in deep learning.  \n",
    "   Example: `optimizer = Adam(learning_rate=0.001)`\n",
    "\n",
    "Each optimizer has pros and cons; choice depends on the problem and dataset.\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "f765ee30-a66f-4e7a-be78-0b89fb3d2d81",
   "metadata": {},
   "source": [
    "17.What is sklearn.linear_model?\n",
    "\n",
    "`sklearn.linear_model` is a module in the scikit-learn library that contains classes and functions for implementing linear models in machine learning. It includes algorithms like:\n",
    "\n",
    "- Linear Regression\n",
    "- Logistic Regression\n",
    "- Ridge Regression\n",
    "- Lasso Regression\n",
    "- ElasticNet\n",
    "\n",
    "These models are used for regression and classification tasks based on linear relationships between input features and target variables.\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "06df18eb-2995-43fc-9164-638bbc049b87",
   "metadata": {},
   "source": [
    "18.What does model.fit() do? What arguments must be given?\n",
    "\n",
    "`model.fit()` trains the machine learning model using the provided data. It adjusts the model parameters to learn patterns from the training dataset.\n",
    "\n",
    "**Arguments:**\n",
    "- `X` — Input features (usually a 2D array or DataFrame).\n",
    "- `y` — Target labels or values (usually a 1D array or Series).\n",
    "\n",
    "Example:  \n",
    "```python\n",
    "model.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "850ce32d-8b85-4ba4-89de-69e74bbaed08",
   "metadata": {},
   "source": [
    "19.What does model.predict() do? What arguments must be given?\n",
    "\n",
    "`model.predict()` uses the trained machine learning model to make predictions on new input data.\n",
    "\n",
    "Arguments:\n",
    "- `X` — Input features (usually a 2D array or DataFrame) for which predictions are to be made.\n",
    "\n",
    "Example:  \n",
    "```python\n",
    "predictions = model.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "2606935c-33f7-4226-b12b-65735d2fe5c2",
   "metadata": {},
   "source": [
    "20.What are continuous and categorical variables?\n",
    "\n",
    "- Continuous variables: Numerical variables that can take any value within a range, including decimals.  \n",
    "  Example: Height, weight, temperature.\n",
    "\n",
    "- Categorical variables: Variables that represent categories or groups and have discrete values.  \n",
    "  Example: Gender, color, type of car.\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "2d3acd9a-6aeb-40c0-ad44-77c95cdcd9cf",
   "metadata": {},
   "source": [
    "21.What is feature scaling? How does it help in Machine Learning?\n",
    "\n",
    "Feature scaling is the process of normalizing or standardizing the range of independent variables (features) so that they have similar scales.\n",
    "\n",
    "It helps machine learning by:\n",
    "- Improving convergence speed during training.\n",
    "- Preventing features with larger scales from dominating the model.\n",
    "- Making algorithms like gradient descent and distance-based methods (e.g., KNN, SVM) work properly.\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "5e5219bd-d010-4167-81ce-82ef91c708fd",
   "metadata": {},
   "source": [
    "22.How do we perform scaling in Python?\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    " Example data\n",
    "X = [[10, 200],\n",
    "     [15, 300],\n",
    "     [20, 400]]\n",
    "\n",
    "Standard Scaling (mean=0, std=1)\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "print(\"Standard Scaled Data:\\n\", X_scaled)\n",
    "\n",
    "Min-Max Scaling (scales data to [0,1] range)\n",
    "minmax_scaler = MinMaxScaler()\n",
    "X_minmax = minmax_scaler.fit_transform(X)\n",
    "print(\"Min-Max Scaled Data:\\n\", X_minmax)\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "665852cf-f289-41ce-81a0-4b8ef8d45f3e",
   "metadata": {},
   "source": [
    "23.What is sklearn.preprocessing?\n",
    "\n",
    "`sklearn.preprocessing` is a module in the scikit-learn library that provides tools to preprocess data before using it in machine learning models.\n",
    "\n",
    "It includes utilities for:\n",
    "- Scaling features (StandardScaler, MinMaxScaler)\n",
    "- Encoding categorical variables (LabelEncoder, OneHotEncoder)\n",
    "- Normalizing data\n",
    "- Binarizing features\n",
    "\n",
    "Preprocessing helps improve model training and performance.\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "ed781015-c6f5-420e-8a21-21b145a60c04",
   "metadata": {},
   "source": [
    "24. How do we split data for model fitting (training and testing) in Python?\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "Assume X = features, y = target variable\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "96842868-0d65-4123-91fc-3c008324a664",
   "metadata": {},
   "source": [
    "25.Explain data encoding?\n",
    "\n",
    "Data encoding is the process of converting categorical data into numerical format so that machine learning algorithms can process it.\n",
    "\n",
    "Common encoding techniques include:\n",
    "- Label Encoding: Assigns each category a unique integer.\n",
    "- One-Hot Encoding: Creates binary columns for each category.\n",
    "- Ordinal Encoding: Assigns integers to categories with an inherent order.\n",
    "\n",
    "Encoding helps algorithms understand and work with categorical variables.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fac14e6b-2e1b-407e-821e-eb0eb2f18f22",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
