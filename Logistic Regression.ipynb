{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b7382e4d-209f-46fd-9363-8e0c9f340048",
   "metadata": {},
   "source": [
    "1.What is Logistic Regression, and how does it differ from Linear Regression?\n",
    "\n",
    "- Logistic Regression is used for classification tasks (e.g., binary outcomes).\n",
    "- It predicts the probability of a class using the sigmoid function.\n",
    "- Linear Regression predicts continuous numerical values.\n",
    "- Logistic Regression output is bounded between 0 and 1; Linear Regression output is unbounded.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f74a2c5d-e9ba-4156-b29f-b8e34fcb8424",
   "metadata": {},
   "source": [
    "2.What is the mathematical equation of Logistic Regression?\n",
    "\n",
    "- The equation is:\n",
    "\n",
    "  P(Y=1) = 1 / (1 + e^-(β₀ + β₁X₁ + β₂X₂ + ... + βnXn))\n",
    "\n",
    "- Where:\n",
    "  - P(Y=1) is the probability of the positive class.\n",
    "  - β₀ is the intercept.\n",
    "  - β₁ to βn are coefficients.\n",
    "  - X₁ to Xn are input features.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb5535ef-4003-4f0f-950c-c2586021423c",
   "metadata": {},
   "source": [
    "3.Why do we use the Sigmoid function in Logistic Regression?\n",
    "\n",
    "- The Sigmoid function maps any real-valued number to a value between 0 and 1.\n",
    "- It converts the linear output into a probability, making it suitable for binary classification.\n",
    "- Helps interpret the output as the likelihood of a class.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "604a739c-c96b-4dc6-89d3-0f4dcc6d754b",
   "metadata": {},
   "source": [
    "4.What is the cost function of Logistic Regression?\n",
    "\n",
    "- The cost function is the **Log Loss** or **Binary Cross-Entropy**:\n",
    "\n",
    "  Cost = -[y * log(p) + (1 - y) * log(1 - p)]\n",
    "\n",
    "- Where:\n",
    "  - y is the actual label (0 or 1)\n",
    "  - p is the predicted probability\n",
    "- It penalizes wrong predictions more when the model is confident but incorrect.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74b628b5-6a55-4624-8060-40d4b3f7ef02",
   "metadata": {},
   "source": [
    "5.What is Regularization in Logistic Regression? Why is it needed?\n",
    "\n",
    "- Regularization adds a penalty to the loss function to reduce model complexity.\n",
    "- It helps prevent overfitting by shrinking large coefficients.\n",
    "- Common types:\n",
    "  - L1 (Lasso): Encourages sparsity.\n",
    "  - L2 (Ridge): Reduces coefficient magnitudes smoothly.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c939a43-7550-40f5-8ea0-55c94071ccb9",
   "metadata": {},
   "source": [
    "6.Explain the difference between Lasso, Ridge, and Elastic Net regression:\n",
    "\n",
    "- **Ridge Regression (L2):** Adds the sum of squared coefficients as a penalty. Shrinks coefficients but keeps all features.\n",
    "\n",
    "- **Lasso Regression (L1):** Adds the sum of absolute values of coefficients. Can shrink some coefficients to zero (feature selection).\n",
    "\n",
    "- **Elastic Net:** Combines both L1 and L2 penalties. Balances between feature selection and coefficient shrinkage.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "017d74f5-fe29-44f2-a78a-b467f0f1e8fa",
   "metadata": {},
   "source": [
    "7.When should we use Elastic Net instead of Lasso or Ridge?\n",
    "\n",
    "- Use Elastic Net when:\n",
    "  - There are many correlated features.\n",
    "  - You want both feature selection (L1) and coefficient shrinkage (L2).\n",
    "  - Lasso drops important features due to correlation.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7085776-beb4-4ee7-9eab-2d9eb167f481",
   "metadata": {},
   "source": [
    "8.What is the impact of the regularization parameter (λ) in Logistic Regression?\n",
    "\n",
    "- λ controls the strength of the regularization penalty.\n",
    "- High λ → Strong regularization → Smaller coefficients → Less overfitting.\n",
    "- Low λ → Weak regularization → Larger coefficients → More complex model.\n",
    "- λ must be tuned to balance bias and variance.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6be1a719-b86f-4e7f-9960-19d85ec0a6aa",
   "metadata": {},
   "source": [
    "9.What are the key assumptions of Logistic Regression?\n",
    "\n",
    "- The outcome is binary (0 or 1).\n",
    "- Observations are independent.\n",
    "- No multicollinearity among predictors.\n",
    "- The relationship between predictors and log-odds is linear.\n",
    "- Large sample size is preferred for stable estimates.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17dbc6bd-1277-4977-8805-8decc2eaf084",
   "metadata": {},
   "source": [
    "10.What are some alternatives to Logistic Regression for classification tasks?\n",
    "\n",
    "- Decision Trees\n",
    "- Random Forest\n",
    "- Support Vector Machines (SVM)\n",
    "- k-Nearest Neighbors (k-NN)\n",
    "- Naive Bayes\n",
    "- Gradient Boosting (e.g., XGBoost, LightGBM)\n",
    "- Neural Networks\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca93bfa4-171d-4f24-a23e-f6fd9b2009e3",
   "metadata": {},
   "source": [
    "11.What are Classification Evaluation Metrics?\n",
    "\n",
    "- **Accuracy:** Proportion of correct predictions.\n",
    "- **Precision:** Correct positive predictions / Total predicted positives.\n",
    "- **Recall (Sensitivity):** Correct positive predictions / Actual positives.\n",
    "- **F1 Score:** Harmonic mean of precision and recall.\n",
    "- **Confusion Matrix:** Table showing TP, TN, FP, FN.\n",
    "- **ROC Curve & AUC:** Trade-off between true positive rate and false positive rate.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3aca8a8d-4516-4d29-aeed-861160ce34aa",
   "metadata": {},
   "source": [
    "12.How does class imbalance affect Logistic Regression?\n",
    "\n",
    "- The model may be biased toward the majority class.\n",
    "- It can lead to poor predictive performance on the minority class.\n",
    "- Metrics like accuracy become misleading.\n",
    "- Requires techniques like resampling, class weighting, or specialized algorithms.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a072698e-9784-4b6c-a6e8-1f9d94446dc6",
   "metadata": {},
   "source": [
    "13.What is Hyperparameter Tuning in Logistic Regression?\n",
    "\n",
    "- It is the process of selecting the best hyperparameters (e.g., regularization strength λ, type of regularization).\n",
    "- Helps improve model performance and prevent overfitting or underfitting.\n",
    "- Common methods: Grid Search, Random Search, or Bayesian Optimization.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "568ae5c0-318f-4f6c-999e-18217a32cfa7",
   "metadata": {},
   "source": [
    "14.What are different solvers in Logistic Regression? Which one should be used?\n",
    "\n",
    "- Common solvers:\n",
    "  - **liblinear:** Good for small datasets, supports L1 and L2 regularization.\n",
    "  - **newton-cg:** Supports L2, good for large datasets.\n",
    "  - **lbfgs:** Supports L2, efficient for large datasets.\n",
    "  - **sag:** Stochastic Average Gradient, good for large datasets.\n",
    "  - **saga:** Supports L1, L2, elastic net, suitable for large datasets.\n",
    "\n",
    "- Which to use:\n",
    "  - Use **liblinear** for small datasets or L1 penalty.\n",
    "  - Use **lbfgs** or **saga** for large datasets and faster convergence.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6f90b53-82f4-4ece-be07-fbfc05d12fa6",
   "metadata": {},
   "source": [
    "15.How is Logistic Regression extended for multiclass classification?\n",
    "\n",
    "- Using strategies like:\n",
    "  - **One-vs-Rest (OvR):** Trains one classifier per class vs all others.\n",
    "  - **Multinomial Logistic Regression:** Directly models probabilities for all classes simultaneously.\n",
    "- Multinomial is preferred when classes are mutually exclusive.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c8030d4-c9d5-43a5-bd73-ea1093250082",
   "metadata": {},
   "source": [
    "16.What are the advantages and disadvantages of Logistic Regression?\n",
    "\n",
    "Advantages:\n",
    "- Simple and easy to implement.\n",
    "- Outputs probabilities, useful for interpretation.\n",
    "- Works well with linearly separable data.\n",
    "- Efficient and fast to train.\n",
    "\n",
    "Disadvantages:\n",
    "- Assumes linear relationship between features and log-odds.\n",
    "- Not suitable for complex, non-linear problems.\n",
    "- Sensitive to outliers and multicollinearity.\n",
    "- Performs poorly with high-dimensional sparse data.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "793f2935-870c-4208-b298-fee90483ebca",
   "metadata": {},
   "source": [
    "17.What are some use cases of Logistic Regression?\n",
    "\n",
    "- Spam email detection (spam or not spam)\n",
    "- Credit risk assessment (default or no default)\n",
    "- Medical diagnosis (disease presence or absence)\n",
    "- Customer churn prediction (churn or stay)\n",
    "- Marketing campaign response (respond or not respond)\n",
    "- Fraud detection (fraudulent or legitimate transactions)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "688fb5da-54b7-46ab-b512-d0635c6b868c",
   "metadata": {},
   "source": [
    "18.What is the difference between Softmax Regression and Logistic Regression?\n",
    "\n",
    "- **Logistic Regression:** Used for binary classification; outputs probability of one class using the sigmoid function.\n",
    "\n",
    "- **Softmax Regression (Multinomial Logistic Regression):** Used for multiclass classification; outputs probabilities for all classes using the softmax function.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66919070-78d0-4d0b-a052-0f4f089f94a4",
   "metadata": {},
   "source": [
    "19.How do we choose between One-vs-Rest (OvR) and Softmax for multiclass classification?\n",
    "\n",
    "- Use **OvR** when:\n",
    "  - Classes are imbalanced.\n",
    "  - Simpler implementation or interpretability needed.\n",
    "  - Each binary classifier can be trained independently.\n",
    "\n",
    "- Use **Softmax** when:\n",
    "  - Classes are mutually exclusive and balanced.\n",
    "  - You want a single model predicting all classes jointly.\n",
    "  - Better performance on complex multiclass problems.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "854ab3c2-830e-490a-a9c6-c0af6f150d7e",
   "metadata": {},
   "source": [
    "20.How do we interpret coefficients in Logistic Regression?\n",
    "\n",
    "- Coefficients represent the change in log-odds of the outcome per unit increase in the predictor.\n",
    "- Positive coefficient → increase in predictor increases odds of class 1.\n",
    "- Negative coefficient → increase in predictor decreases odds of class 1.\n",
    "- Exponentiating coefficients (e^coef) gives the odds ratio.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecc029e2-fc5f-4602-a465-9ef0595a3c66",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a7732efd-6cea-4e73-bf6a-e3732fe6b829",
   "metadata": {},
   "source": [
    "                        PRACTICAL"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b89ef58-2b5d-4268-924f-cd74ed8dd7f7",
   "metadata": {},
   "source": [
    "1. Write a Python program that loads a dataset, splits it into training and testing sets, applies Logistic\n",
    "Regression, and prints the model accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4279f3f3-fbff-468e-8432-397a9424f984",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 1.0\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Load dataset\n",
    "data = load_iris()\n",
    "X, y = data.data, data.target\n",
    "\n",
    "# Split into train and test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Initialize and train model\n",
    "model = LogisticRegression(max_iter=200)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Predict and evaluate\n",
    "y_pred = model.predict(X_test)\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cc44824-6a80-4a03-8d68-affcfdd6290b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c474fbdc-9564-4eaf-8dbe-26bfc41395aa",
   "metadata": {},
   "source": [
    "2.Write a Python program to apply L1 regularization (Lasso) on a dataset using LogisticRegression(penalty='l1')\n",
    "and print the model accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "35ec3776-285c-40af-b022-6d73d152c096",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy with L1 regularization: 1.0\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Load dataset\n",
    "data = load_iris()\n",
    "X, y = data.data, data.target\n",
    "\n",
    "# Split into train and test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Initialize and train Logistic Regression with L1 penalty (solver must support L1)\n",
    "model = LogisticRegression(penalty='l1', solver='saga', max_iter=5000)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Predict and evaluate\n",
    "y_pred = model.predict(X_test)\n",
    "print(\"Accuracy with L1 regularization:\", accuracy_score(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "effb25df-3aa7-4bb1-948f-a1cd4ab6a636",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "13618006-07a1-419b-9b52-075ea5c87422",
   "metadata": {},
   "source": [
    "3.Write a Python program to train Logistic Regression with L2 regularization (Ridge) using\n",
    "LogisticRegression(penalty='l2'). Print model accuracy and coefficients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "915a701f-7bcb-4e3d-8c78-39756dbfb2a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy with L2 regularization: 1.0\n",
      "Model coefficients:\n",
      " [[-0.39347744  0.96248927 -2.37513361 -0.99874691]\n",
      " [ 0.50844553 -0.2548109  -0.21300984 -0.77574616]\n",
      " [-0.11496809 -0.70767836  2.58814346  1.77449307]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Load dataset\n",
    "data = load_iris()\n",
    "X, y = data.data, data.target\n",
    "\n",
    "# Split into train and test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train Logistic Regression with L2 penalty\n",
    "model = LogisticRegression(penalty='l2', solver='lbfgs', max_iter=5000)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Predict and evaluate\n",
    "y_pred = model.predict(X_test)\n",
    "print(\"Accuracy with L2 regularization:\", accuracy_score(y_test, y_pred))\n",
    "print(\"Model coefficients:\\n\", model.coef_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "316f6688-da11-45a5-a79d-60f8cf5a06e0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "594f940b-5be0-4ea8-81d0-98e9a561f119",
   "metadata": {},
   "source": [
    "4.Write a Python program to train Logistic Regression with Elastic Net Regularization (penalty='elasticnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "05688767-3664-4d89-a7b7-9eebb3fa88c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy with Elastic Net regularization: 1.0\n",
      "Model coefficients:\n",
      " [[ 0.          1.237146   -2.52849355 -0.58997124]\n",
      " [ 0.13638431  0.          0.         -0.50809068]\n",
      " [-0.50730375 -0.75607488  2.87854757  2.09806143]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Load dataset\n",
    "data = load_iris()\n",
    "X, y = data.data, data.target\n",
    "\n",
    "# Split into train and test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train Logistic Regression with Elastic Net penalty (solver='saga' required)\n",
    "model = LogisticRegression(penalty='elasticnet', solver='saga', l1_ratio=0.5, max_iter=5000)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Predict and evaluate\n",
    "y_pred = model.predict(X_test)\n",
    "print(\"Accuracy with Elastic Net regularization:\", accuracy_score(y_test, y_pred))\n",
    "print(\"Model coefficients:\\n\", model.coef_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e664a72e-67f8-401c-b8a1-445e2513d117",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1e845a5c-be3f-44f0-b675-671a10514f89",
   "metadata": {},
   "source": [
    "5.Write a Python program to train a Logistic Regression model for multiclass classification using\n",
    "multi_class='ovr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e99a15a8-7355-4abe-a780-709077e86fb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy (OVR): 0.9666666666666667\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\DELL\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1256: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. Use OneVsRestClassifier(LogisticRegression(..)) instead. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Load dataset\n",
    "data = load_iris()\n",
    "X, y = data.data, data.target\n",
    "\n",
    "# Split data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train Logistic Regression with one-vs-rest (ovr) strategy\n",
    "model = LogisticRegression(multi_class='ovr', solver='lbfgs', max_iter=5000)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Predict and evaluate\n",
    "y_pred = model.predict(X_test)\n",
    "print(\"Accuracy (OVR):\", accuracy_score(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b1157b6-7765-4ec7-a131-5c041f6e5576",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e9ba7586-f252-446b-af81-c88de5235360",
   "metadata": {},
   "source": [
    "6.Write a Python program to apply GridSearchCV to tune the hyperparameters (C and penalty) of Logistic\n",
    "Regression. Print the best parameters and accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "574d04d5-4644-4d83-a07b-16da512c36d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\DELL\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "C:\\Users\\DELL\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "C:\\Users\\DELL\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "C:\\Users\\DELL\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "C:\\Users\\DELL\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "C:\\Users\\DELL\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "C:\\Users\\DELL\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "C:\\Users\\DELL\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "C:\\Users\\DELL\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "C:\\Users\\DELL\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "C:\\Users\\DELL\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "C:\\Users\\DELL\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "C:\\Users\\DELL\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "C:\\Users\\DELL\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "C:\\Users\\DELL\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "C:\\Users\\DELL\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "C:\\Users\\DELL\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "C:\\Users\\DELL\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "C:\\Users\\DELL\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "C:\\Users\\DELL\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "C:\\Users\\DELL\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "C:\\Users\\DELL\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "C:\\Users\\DELL\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "C:\\Users\\DELL\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "C:\\Users\\DELL\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "C:\\Users\\DELL\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "C:\\Users\\DELL\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "C:\\Users\\DELL\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "C:\\Users\\DELL\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "C:\\Users\\DELL\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "C:\\Users\\DELL\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "C:\\Users\\DELL\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "C:\\Users\\DELL\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "C:\\Users\\DELL\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "C:\\Users\\DELL\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "C:\\Users\\DELL\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "C:\\Users\\DELL\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "C:\\Users\\DELL\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "C:\\Users\\DELL\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "C:\\Users\\DELL\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "C:\\Users\\DELL\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "C:\\Users\\DELL\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "C:\\Users\\DELL\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "C:\\Users\\DELL\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "C:\\Users\\DELL\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "C:\\Users\\DELL\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "C:\\Users\\DELL\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "C:\\Users\\DELL\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "C:\\Users\\DELL\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "C:\\Users\\DELL\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "C:\\Users\\DELL\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "C:\\Users\\DELL\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "C:\\Users\\DELL\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "C:\\Users\\DELL\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "C:\\Users\\DELL\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "C:\\Users\\DELL\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "C:\\Users\\DELL\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "C:\\Users\\DELL\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "C:\\Users\\DELL\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "C:\\Users\\DELL\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "C:\\Users\\DELL\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "C:\\Users\\DELL\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "C:\\Users\\DELL\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "C:\\Users\\DELL\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "C:\\Users\\DELL\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "C:\\Users\\DELL\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "C:\\Users\\DELL\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "C:\\Users\\DELL\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "C:\\Users\\DELL\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "C:\\Users\\DELL\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "C:\\Users\\DELL\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "C:\\Users\\DELL\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "C:\\Users\\DELL\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "C:\\Users\\DELL\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "C:\\Users\\DELL\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "C:\\Users\\DELL\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "C:\\Users\\DELL\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "C:\\Users\\DELL\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "C:\\Users\\DELL\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "C:\\Users\\DELL\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "C:\\Users\\DELL\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "C:\\Users\\DELL\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "C:\\Users\\DELL\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "C:\\Users\\DELL\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "C:\\Users\\DELL\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "C:\\Users\\DELL\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "C:\\Users\\DELL\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "C:\\Users\\DELL\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "C:\\Users\\DELL\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "C:\\Users\\DELL\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "C:\\Users\\DELL\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "C:\\Users\\DELL\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "C:\\Users\\DELL\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "C:\\Users\\DELL\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "C:\\Users\\DELL\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "C:\\Users\\DELL\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "C:\\Users\\DELL\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "C:\\Users\\DELL\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "C:\\Users\\DELL\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "C:\\Users\\DELL\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "C:\\Users\\DELL\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "C:\\Users\\DELL\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "C:\\Users\\DELL\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "C:\\Users\\DELL\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "C:\\Users\\DELL\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "C:\\Users\\DELL\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "C:\\Users\\DELL\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "C:\\Users\\DELL\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "C:\\Users\\DELL\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "C:\\Users\\DELL\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "C:\\Users\\DELL\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "C:\\Users\\DELL\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "C:\\Users\\DELL\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "C:\\Users\\DELL\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "C:\\Users\\DELL\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "C:\\Users\\DELL\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "C:\\Users\\DELL\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "C:\\Users\\DELL\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "C:\\Users\\DELL\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "C:\\Users\\DELL\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters: {'C': 10, 'l1_ratio': 0, 'penalty': 'l2'}\n",
      "Accuracy with best parameters: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\DELL\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Load dataset\n",
    "data = load_iris()\n",
    "X, y = data.data, data.target\n",
    "\n",
    "# Split data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Define model\n",
    "model = LogisticRegression(solver='saga', max_iter=5000)\n",
    "\n",
    "# Define hyperparameters grid\n",
    "param_grid = {\n",
    "    'C': [0.01, 0.1, 1, 10],\n",
    "    'penalty': ['l1', 'l2', 'elasticnet'],\n",
    "    'l1_ratio': [0, 0.5, 1]  # Only used if penalty='elasticnet'\n",
    "}\n",
    "\n",
    "# Setup GridSearchCV\n",
    "grid = GridSearchCV(model, param_grid, cv=5, scoring='accuracy', refit=True)\n",
    "\n",
    "# Fit GridSearch\n",
    "grid.fit(X_train, y_train)\n",
    "\n",
    "# Predict and evaluate\n",
    "y_pred = grid.predict(X_test)\n",
    "print(\"Best parameters:\", grid.best_params_)\n",
    "print(\"Accuracy with best parameters:\", accuracy_score(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "710430ea-7638-4b6b-8f5d-ea81d262a1cf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a12c411d-2db5-4f5e-94e8-b227c3bd21d6",
   "metadata": {},
   "source": [
    "7.Write a Python program to evaluate Logistic Regression using Stratified K-Fold Cross-Validation. Print the\n",
    "average accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "340116b3-9979-443b-9bd7-201a3233386a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy scores for each fold: [1.         0.96666667 0.93333333 1.         0.93333333]\n",
      "Average accuracy: 0.9666666666666668\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import StratifiedKFold, cross_val_score\n",
    "import numpy as np\n",
    "\n",
    "# Load dataset\n",
    "data = load_iris()\n",
    "X, y = data.data, data.target\n",
    "\n",
    "# Initialize model\n",
    "model = LogisticRegression(max_iter=5000, solver='lbfgs')\n",
    "\n",
    "# Stratified K-Fold CV\n",
    "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "scores = cross_val_score(model, X, y, cv=skf, scoring='accuracy')\n",
    "\n",
    "print(\"Accuracy scores for each fold:\", scores)\n",
    "print(\"Average accuracy:\", np.mean(scores))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b521a4a7-8a9d-4cba-aebc-d5e6ddee2be7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e25f42a3-5530-4d83-a02c-64cfae03d740",
   "metadata": {},
   "source": [
    "8.Write a Python program to load a dataset from a CSV file, apply Logistic Regression, and evaluate its\n",
    "accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8459ecba-2ba2-4af2-8829-f6761a0c47d9",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'your_dataset.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 7\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmetrics\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m accuracy_score\n\u001b[0;32m      6\u001b[0m \u001b[38;5;66;03m# Load dataset from CSV file (replace 'your_dataset.csv' with your file path)\u001b[39;00m\n\u001b[1;32m----> 7\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43myour_dataset.csv\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;66;03m# Assuming last column is the target variable\u001b[39;00m\n\u001b[0;32m     10\u001b[0m X \u001b[38;5;241m=\u001b[39m data\u001b[38;5;241m.\u001b[39miloc[:, :\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1026\u001b[0m, in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[0;32m   1013\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[0;32m   1014\u001b[0m     dialect,\n\u001b[0;32m   1015\u001b[0m     delimiter,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1022\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[0;32m   1023\u001b[0m )\n\u001b[0;32m   1024\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[1;32m-> 1026\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:620\u001b[0m, in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    617\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[0;32m    619\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[1;32m--> 620\u001b[0m parser \u001b[38;5;241m=\u001b[39m \u001b[43mTextFileReader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    622\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[0;32m    623\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1620\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m   1617\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m   1619\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m-> 1620\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1880\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[1;34m(self, f, engine)\u001b[0m\n\u001b[0;32m   1878\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[0;32m   1879\u001b[0m         mode \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m-> 1880\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1881\u001b[0m \u001b[43m    \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1882\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1883\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1884\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcompression\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1885\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmemory_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmemory_map\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1886\u001b[0m \u001b[43m    \u001b[49m\u001b[43mis_text\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_text\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1887\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding_errors\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstrict\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1888\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstorage_options\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1889\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1890\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1891\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\io\\common.py:873\u001b[0m, in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    868\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[0;32m    869\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[0;32m    870\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[0;32m    871\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[0;32m    872\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[1;32m--> 873\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[0;32m    874\u001b[0m \u001b[43m            \u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    875\u001b[0m \u001b[43m            \u001b[49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    876\u001b[0m \u001b[43m            \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    877\u001b[0m \u001b[43m            \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    878\u001b[0m \u001b[43m            \u001b[49m\u001b[43mnewline\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    879\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    880\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    881\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[0;32m    882\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'your_dataset.csv'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Load dataset from CSV file (replace 'your_dataset.csv' with your file path)\n",
    "data = pd.read_csv('your_dataset.csv')\n",
    "\n",
    "# Assuming last column is the target variable\n",
    "X = data.iloc[:, :-1]\n",
    "y = data.iloc[:, -1]\n",
    "\n",
    "# Split data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train Logistic Regression\n",
    "model = LogisticRegression(max_iter=5000)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Predict and evaluate\n",
    "y_pred = model.predict(X_test)\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81709a4f-2836-48b9-b185-5380f85afbea",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b155520f-9511-4a2a-a984-c81e2f9baf02",
   "metadata": {},
   "source": [
    "9.Write a Python program to apply RandomizedSearchCV for tuning hyperparameters (C, penalty, solver) in\n",
    "Logistic Regression. Print the best parameters and accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fcc40539-4cb1-492a-976e-1b8d53af2ea6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\DELL\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "C:\\Users\\DELL\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "C:\\Users\\DELL\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "C:\\Users\\DELL\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "C:\\Users\\DELL\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "C:\\Users\\DELL\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "C:\\Users\\DELL\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "C:\\Users\\DELL\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "C:\\Users\\DELL\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "C:\\Users\\DELL\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "C:\\Users\\DELL\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "C:\\Users\\DELL\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "C:\\Users\\DELL\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "C:\\Users\\DELL\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "C:\\Users\\DELL\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "C:\\Users\\DELL\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "C:\\Users\\DELL\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "C:\\Users\\DELL\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "C:\\Users\\DELL\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "C:\\Users\\DELL\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "C:\\Users\\DELL\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "C:\\Users\\DELL\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "C:\\Users\\DELL\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "C:\\Users\\DELL\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "C:\\Users\\DELL\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "C:\\Users\\DELL\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "C:\\Users\\DELL\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "C:\\Users\\DELL\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "C:\\Users\\DELL\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "C:\\Users\\DELL\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "C:\\Users\\DELL\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "C:\\Users\\DELL\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "C:\\Users\\DELL\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "C:\\Users\\DELL\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "C:\\Users\\DELL\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "C:\\Users\\DELL\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "C:\\Users\\DELL\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "C:\\Users\\DELL\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "C:\\Users\\DELL\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "C:\\Users\\DELL\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "C:\\Users\\DELL\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "C:\\Users\\DELL\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "C:\\Users\\DELL\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "C:\\Users\\DELL\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "C:\\Users\\DELL\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "C:\\Users\\DELL\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "C:\\Users\\DELL\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "C:\\Users\\DELL\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "C:\\Users\\DELL\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "C:\\Users\\DELL\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "C:\\Users\\DELL\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "C:\\Users\\DELL\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "C:\\Users\\DELL\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "C:\\Users\\DELL\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "C:\\Users\\DELL\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters: {'C': np.float64(3.7554011884736247), 'l1_ratio': 0, 'penalty': 'elasticnet', 'solver': 'saga'}\n",
      "Accuracy with best parameters: 1.0\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "from scipy.stats import uniform\n",
    "import numpy as np\n",
    "\n",
    "# Load dataset\n",
    "data = load_iris()\n",
    "X, y = data.data, data.target\n",
    "\n",
    "# Split data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Define model\n",
    "model = LogisticRegression(max_iter=5000)\n",
    "\n",
    "# Define hyperparameter distributions\n",
    "param_dist = {\n",
    "    'C': uniform(0.01, 10),\n",
    "    'penalty': ['l1', 'l2', 'elasticnet'],\n",
    "    'solver': ['saga'],\n",
    "    'l1_ratio': [0, 0.5, 1]  # Only used if penalty='elasticnet'\n",
    "}\n",
    "\n",
    "# Setup RandomizedSearchCV\n",
    "random_search = RandomizedSearchCV(model, param_distributions=param_dist, n_iter=20, cv=5, scoring='accuracy', random_state=42, refit=True)\n",
    "\n",
    "# Fit RandomizedSearchCV\n",
    "random_search.fit(X_train, y_train)\n",
    "\n",
    "# Predict and evaluate\n",
    "y_pred = random_search.predict(X_test)\n",
    "print(\"Best parameters:\", random_search.best_params_)\n",
    "print(\"Accuracy with best parameters:\", accuracy_score(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4266869d-acd3-4a12-a27b-fc0ff52d84a2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8b6193f8-dca2-490d-b278-9aea281350b8",
   "metadata": {},
   "source": [
    "10.Write a Python program to implement One-vs-One (OvO) Multiclass Logistic Regression and print accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "386726ac-2167-4cba-aa53-93acdb0dd20e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy (One-vs-One): 1.0\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.multiclass import OneVsOneClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Load dataset\n",
    "data = load_iris()\n",
    "X, y = data.data, data.target\n",
    "\n",
    "# Split dataset\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Initialize OvO Logistic Regression\n",
    "ovo_model = OneVsOneClassifier(LogisticRegression(max_iter=5000, solver='lbfgs'))\n",
    "\n",
    "# Train model\n",
    "ovo_model.fit(X_train, y_train)\n",
    "\n",
    "# Predict and evaluate\n",
    "y_pred = ovo_model.predict(X_test)\n",
    "print(\"Accuracy (One-vs-One):\", accuracy_score(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "910095b7-d331-4156-af8f-f26877463e11",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2337d4d1-23f2-4e69-9cf6-95ddd2517af3",
   "metadata": {},
   "source": [
    "11.Write a Python program to train a Logistic Regression model and visualize the confusion matrix for binary\n",
    "classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fb3d6563-6792-42b6-9442-ec1a3b552366",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "\n",
    "# Generate synthetic binary classification data\n",
    "X, y = make_classification(n_samples=300, n_features=5, n_classes=2, random_state=42)\n",
    "\n",
    "# Split data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train Logistic Regression model\n",
    "model = LogisticRegression(max_iter=5000)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Predict\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Compute confusion matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "# Visualize confusion matrix\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm)\n",
    "disp.plot(cmap=plt.cm.Blues)\n",
    "plt.title(\"Confusion Matrix - Logistic Regression\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ce5478f-0879-4dbb-b688-e71cb6ef267b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e3629efe-fe52-4a47-8b34-91075222da8b",
   "metadata": {},
   "source": [
    "12.Write a Python program to train a Logistic Regression model and evaluate its performance using Precision,\n",
    "Recall, and F1-Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fd61212d-1255-4fa6-bff1-c4ae31576a39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 1.0000\n",
      "Recall: 1.0000\n",
      "F1-Score: 1.0000\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import make_classification\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "\n",
    "# Generate synthetic binary classification data\n",
    "X, y = make_classification(n_samples=300, n_features=5, n_classes=2, random_state=42)\n",
    "\n",
    "# Split data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train Logistic Regression model\n",
    "model = LogisticRegression(max_iter=5000)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Predict\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Evaluate performance\n",
    "precision = precision_score(y_test, y_pred)\n",
    "recall = recall_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "\n",
    "print(f\"Precision: {precision:.4f}\")\n",
    "print(f\"Recall: {recall:.4f}\")\n",
    "print(f\"F1-Score: {f1:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2988067b-3c69-4837-b3a7-ef8a1152c86c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "cfd39edb-7e2e-4a37-a608-86ed0c10fd9d",
   "metadata": {},
   "source": [
    "13.Write a Python program to train a Logistic Regression model on imbalanced data and apply class weights to\n",
    "improve model performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3ffcc8ca-8429-48d7-979e-0aec33aa21bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original class distribution: Counter({np.int64(0): 900, np.int64(1): 100})\n",
      "Classification report without class weights:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.97      0.95       177\n",
      "           1       0.69      0.48      0.56        23\n",
      "\n",
      "    accuracy                           0.92       200\n",
      "   macro avg       0.81      0.73      0.76       200\n",
      "weighted avg       0.91      0.92      0.91       200\n",
      "\n",
      "Classification report with class weights:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.87      0.92       177\n",
      "           1       0.45      0.83      0.58        23\n",
      "\n",
      "    accuracy                           0.86       200\n",
      "   macro avg       0.71      0.85      0.75       200\n",
      "weighted avg       0.91      0.86      0.88       200\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import make_classification\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from collections import Counter\n",
    "\n",
    "# Generate imbalanced dataset\n",
    "X, y = make_classification(n_samples=1000, n_features=5, weights=[0.9, 0.1], flip_y=0, random_state=42)\n",
    "\n",
    "print(\"Original class distribution:\", Counter(y))\n",
    "\n",
    "# Split data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train Logistic Regression without class weights\n",
    "model_no_weights = LogisticRegression(max_iter=5000)\n",
    "model_no_weights.fit(X_train, y_train)\n",
    "y_pred_no_weights = model_no_weights.predict(X_test)\n",
    "\n",
    "print(\"Classification report without class weights:\")\n",
    "print(classification_report(y_test, y_pred_no_weights))\n",
    "\n",
    "# Train Logistic Regression with class weights\n",
    "model_weights = LogisticRegression(class_weight='balanced', max_iter=5000)\n",
    "model_weights.fit(X_train, y_train)\n",
    "y_pred_weights = model_weights.predict(X_test)\n",
    "\n",
    "print(\"Classification report with class weights:\")\n",
    "print(classification_report(y_test, y_pred_weights))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc1e48b1-6a15-4edd-aae3-f51608e32254",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3db883cf-4f48-44bb-87af-d4a1f65565f3",
   "metadata": {},
   "source": [
    "14.Write a Python program to train Logistic Regression on the Titanic dataset, handle missing values, and\n",
    "evaluate performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b52355cd-8e47-47c9-9d2c-2527ee933d44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8100558659217877\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\DELL\\AppData\\Local\\Temp\\ipykernel_5096\\3042475491.py:12: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  data['Age'].fillna(data['Age'].median(), inplace=True)\n",
      "C:\\Users\\DELL\\AppData\\Local\\Temp\\ipykernel_5096\\3042475491.py:14: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  data['Embarked'].fillna(data['Embarked'].mode()[0], inplace=True)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Load Titanic dataset (replace with your local path or URL)\n",
    "url = \"https://raw.githubusercontent.com/datasciencedojo/datasets/master/titanic.csv\"\n",
    "data = pd.read_csv(url)\n",
    "\n",
    "# Handle missing values: fill Age with median, drop Cabin, fill Embarked with mode\n",
    "data['Age'].fillna(data['Age'].median(), inplace=True)\n",
    "data.drop(columns=['Cabin', 'Ticket', 'Name'], inplace=True)\n",
    "data['Embarked'].fillna(data['Embarked'].mode()[0], inplace=True)\n",
    "\n",
    "# Convert categorical columns using LabelEncoder\n",
    "le = LabelEncoder()\n",
    "data['Sex'] = le.fit_transform(data['Sex'])\n",
    "data['Embarked'] = le.fit_transform(data['Embarked'])\n",
    "\n",
    "# Features and target\n",
    "X = data.drop('Survived', axis=1)\n",
    "y = data['Survived']\n",
    "\n",
    "# Split data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train Logistic Regression\n",
    "model = LogisticRegression(max_iter=5000)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Predict and evaluate\n",
    "y_pred = model.predict(X_test)\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83903656-1b06-431c-90be-263944fa6234",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2214559c-4f73-4bac-b2bf-78dbfbc73a4b",
   "metadata": {},
   "source": [
    "15.Write a Python program to apply feature scaling (Standardization) before training a Logistic Regression\n",
    "model. Evaluate its accuracy and compare results with and without scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fdf4848c-41aa-489e-89c4-3dffcf2c8ebb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy without scaling: 0.8900\n",
      "Accuracy with scaling: 0.8900\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import make_classification\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Generate synthetic data\n",
    "X, y = make_classification(n_samples=500, n_features=5, random_state=42)\n",
    "\n",
    "# Split data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Logistic Regression without scaling\n",
    "model_no_scaling = LogisticRegression(max_iter=5000)\n",
    "model_no_scaling.fit(X_train, y_train)\n",
    "y_pred_no_scaling = model_no_scaling.predict(X_test)\n",
    "acc_no_scaling = accuracy_score(y_test, y_pred_no_scaling)\n",
    "\n",
    "# Apply StandardScaler\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Logistic Regression with scaling\n",
    "model_scaling = LogisticRegression(max_iter=5000)\n",
    "model_scaling.fit(X_train_scaled, y_train)\n",
    "y_pred_scaling = model_scaling.predict(X_test_scaled)\n",
    "acc_scaling = accuracy_score(y_test, y_pred_scaling)\n",
    "\n",
    "print(f\"Accuracy without scaling: {acc_no_scaling:.4f}\")\n",
    "print(f\"Accuracy with scaling: {acc_scaling:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4aecfc58-dd59-493a-9d24-7590aa00192b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b7a70419-f5ad-4b51-922c-841b45fd3a95",
   "metadata": {},
   "source": [
    "16.Write a Python program to train Logistic Regression and evaluate its performance using ROC-AUC score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2f41febe-c567-4d74-a0c7-2f050de941a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC-AUC score: 0.9647\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import make_classification\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "# Generate synthetic binary classification data\n",
    "X, y = make_classification(n_samples=500, n_features=5, random_state=42)\n",
    "\n",
    "# Split data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train Logistic Regression model\n",
    "model = LogisticRegression(max_iter=5000)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Predict probabilities for positive class\n",
    "y_proba = model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# Calculate ROC-AUC score\n",
    "roc_auc = roc_auc_score(y_test, y_proba)\n",
    "print(f\"ROC-AUC score: {roc_auc:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20b86724-dad5-4e36-8b1e-6193e384db7a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8b7a3cd2-4872-42c9-9101-e423dbfa2afb",
   "metadata": {},
   "source": [
    "17.Write a Python program to train Logistic Regression using a custom learning rate (C=0.5) and evaluate\n",
    "accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "11739715-1c8f-4b29-88c9-c6a37e850aa7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8900\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import make_classification\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Generate synthetic binary classification data\n",
    "X, y = make_classification(n_samples=500, n_features=5, random_state=42)\n",
    "\n",
    "# Split data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train Logistic Regression with C=0.5 (inverse of regularization strength)\n",
    "model = LogisticRegression(C=0.5, max_iter=5000)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Predict and evaluate\n",
    "y_pred = model.predict(X_test)\n",
    "print(f\"Accuracy: {accuracy_score(y_test, y_pred):.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdb52e86-e3dd-445f-9189-c16c63657a48",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "25643f01-ad01-43a6-ad21-77f5dd290ceb",
   "metadata": {},
   "source": [
    "18.Write a Python program to train Logistic Regression and identify important features based on model\n",
    "coefficients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "52b9b730-6dbc-4613-8805-cd204baf7a76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature_0: 2.2176\n",
      "Feature_1: 0.1170\n",
      "Feature_2: -0.2180\n",
      "Feature_3: 0.5934\n",
      "Feature_4: -0.0684\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Generate synthetic data\n",
    "X, y = make_classification(n_samples=500, n_features=5, random_state=42)\n",
    "feature_names = [f\"Feature_{i}\" for i in range(X.shape[1])]\n",
    "\n",
    "# Split data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train Logistic Regression\n",
    "model = LogisticRegression(max_iter=5000)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Get feature coefficients\n",
    "coefficients = model.coef_[0]\n",
    "\n",
    "# Print features with coefficients\n",
    "for feature, coef in zip(feature_names, coefficients):\n",
    "    print(f\"{feature}: {coef:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "add777aa-f038-4e86-be9e-2c9ebc10add3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "55908466-1a92-4832-8bfe-b3abe69b9286",
   "metadata": {},
   "source": [
    "19.Write a Python program to train Logistic Regression and evaluate its performance using Cohen’s Kappa\n",
    "Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0d139dde-d973-471f-b138-1f32be4dccf6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cohen's Kappa Score: 0.7800\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import make_classification\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import cohen_kappa_score\n",
    "\n",
    "# Generate synthetic binary classification data\n",
    "X, y = make_classification(n_samples=500, n_features=5, random_state=42)\n",
    "\n",
    "# Split data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train Logistic Regression\n",
    "model = LogisticRegression(max_iter=5000)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Predict\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Calculate Cohen's Kappa Score\n",
    "kappa = cohen_kappa_score(y_test, y_pred)\n",
    "print(f\"Cohen's Kappa Score: {kappa:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bada893e-8ced-4927-b9dd-60fb7ea5f8c0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5c24f5dc-9e0d-4f21-b92b-d14f1b15429d",
   "metadata": {},
   "source": [
    "20.Write a Python program to train Logistic Regression and visualize the Precision-Recall Curve for binary\n",
    "classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "00c09244-4960-4904-ae83-d08ab9d257dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import precision_recall_curve, PrecisionRecallDisplay\n",
    "\n",
    "# Generate synthetic binary classification data\n",
    "X, y = make_classification(n_samples=500, n_features=5, random_state=42)\n",
    "\n",
    "# Split data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train Logistic Regression\n",
    "model = LogisticRegression(max_iter=5000)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Predict probabilities for positive class\n",
    "y_scores = model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# Compute precision-recall curve\n",
    "precision, recall, _ = precision_recall_curve(y_test, y_scores)\n",
    "\n",
    "# Plot precision-recall curve\n",
    "disp = PrecisionRecallDisplay(precision=precision, recall=recall)\n",
    "disp.plot()\n",
    "plt.title(\"Precision-Recall Curve\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2544a0be-f9bc-4842-93e6-c993b01fa5ac",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3f99670d-aa75-4aca-b16d-c325a440579d",
   "metadata": {},
   "source": [
    "21.Write a Python program to train Logistic Regression with different solvers (liblinear, saga, lbfgs) and compare\n",
    "their accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ea062dad-4bf0-4f74-9bb6-65dc01ece738",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Solver: liblinear -> Accuracy: 0.8900\n",
      "Solver: saga -> Accuracy: 0.8900\n",
      "Solver: lbfgs -> Accuracy: 0.8900\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import make_classification\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Generate synthetic data\n",
    "X, y = make_classification(n_samples=500, n_features=5, random_state=42)\n",
    "\n",
    "# Split data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# List of solvers to compare\n",
    "solvers = ['liblinear', 'saga', 'lbfgs']\n",
    "\n",
    "# Train and evaluate models with different solvers\n",
    "for solver in solvers:\n",
    "    model = LogisticRegression(solver=solver, max_iter=5000)\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    acc = accuracy_score(y_test, y_pred)\n",
    "    print(f\"Solver: {solver} -> Accuracy: {acc:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbacbedc-2ad4-49c4-b71c-1bc1630ec73e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "aa02f870-e90a-42fb-a1a8-bc47d813a02f",
   "metadata": {},
   "source": [
    "22.Write a Python program to train Logistic Regression and evaluate its performance using Matthews\n",
    "Correlation Coefficient (MCC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "aaa92ce1-447d-48ab-9607-32cb486926bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matthews Correlation Coefficient (MCC): 0.7814\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import make_classification\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import matthews_corrcoef\n",
    "\n",
    "# Generate synthetic binary classification data\n",
    "X, y = make_classification(n_samples=500, n_features=5, random_state=42)\n",
    "\n",
    "# Split data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train Logistic Regression\n",
    "model = LogisticRegression(max_iter=5000)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Predict\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Calculate MCC\n",
    "mcc = matthews_corrcoef(y_test, y_pred)\n",
    "print(f\"Matthews Correlation Coefficient (MCC): {mcc:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdf40b22-7c50-4087-b99c-15697e3ec2a1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f03c0722-41b7-4c4f-b5b4-80bc51ff8071",
   "metadata": {},
   "source": [
    "23.Write a Python program to train Logistic Regression on both raw and standardized data. Compare their\n",
    "accuracy to see the impact of feature scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d393f6a4-8343-49b3-91b3-c8c2a7dc3e30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on raw data: 0.8900\n",
      "Accuracy on standardized data: 0.8900\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import make_classification\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Generate synthetic data\n",
    "X, y = make_classification(n_samples=500, n_features=5, random_state=42)\n",
    "\n",
    "# Split data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Logistic Regression on raw data\n",
    "model_raw = LogisticRegression(max_iter=5000)\n",
    "model_raw.fit(X_train, y_train)\n",
    "y_pred_raw = model_raw.predict(X_test)\n",
    "acc_raw = accuracy_score(y_test, y_pred_raw)\n",
    "\n",
    "# Standardize data\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Logistic Regression on scaled data\n",
    "model_scaled = LogisticRegression(max_iter=5000)\n",
    "model_scaled.fit(X_train_scaled, y_train)\n",
    "y_pred_scaled = model_scaled.predict(X_test_scaled)\n",
    "acc_scaled = accuracy_score(y_test, y_pred_scaled)\n",
    "\n",
    "print(f\"Accuracy on raw data: {acc_raw:.4f}\")\n",
    "print(f\"Accuracy on standardized data: {acc_scaled:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cbe0368-6f0a-4b42-a957-cd2482bd5cc8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a09b8348-cd54-450d-9ffe-887c7c8ca203",
   "metadata": {},
   "source": [
    "24.Write a Python program to train Logistic Regression and find the optimal C (regularization strength) using\n",
    "cross-validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e110b7a2-5bd1-4b93-82b4-982455199122",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best C: 0.01\n",
      "Test set accuracy with best C: 0.8700\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import make_classification\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split\n",
    "\n",
    "# Generate synthetic data\n",
    "X, y = make_classification(n_samples=500, n_features=5, random_state=42)\n",
    "\n",
    "# Split data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Logistic Regression model\n",
    "model = LogisticRegression(max_iter=5000)\n",
    "\n",
    "# Hyperparameter grid for C\n",
    "param_grid = {'C': [0.01, 0.1, 1, 10, 100]}\n",
    "\n",
    "# GridSearchCV with 5-fold cross-validation\n",
    "grid_search = GridSearchCV(model, param_grid, cv=5, scoring='accuracy')\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Best parameter and accuracy on test set\n",
    "best_C = grid_search.best_params_['C']\n",
    "best_model = grid_search.best_estimator_\n",
    "test_accuracy = best_model.score(X_test, y_test)\n",
    "\n",
    "print(f\"Best C: {best_C}\")\n",
    "print(f\"Test set accuracy with best C: {test_accuracy:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a867fd6b-99cf-4547-80b0-45e162ac2aee",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ad79018d-83dc-4fc7-a771-e79538f533b3",
   "metadata": {},
   "source": [
    "25.Write a Python program to train Logistic Regression, save the trained model using joblib, and load it again to\n",
    "make predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "912e374e-aeea-40d1-bb34-8ef90158648c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions: [0 1 1 1 0 1 1 0 0 1 1 0 0 1 1 1 0 0 0 1 1 1 0 1 0 0 0 0 0 1 0 0 0 0 1 0 0\n",
      " 1 0 1 0 1 1 0 1 0 1 1 1 0 0 0 1 0 1 0 1 0 0 1 1 1 1 0 1 1 1 1 0 0 1 0 1 1\n",
      " 0 0 0 0 1 1 1 0 1 1 0 1 0 0 0 1 1 1 0 1 0 1 0 0 1 0]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import make_classification\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "import joblib\n",
    "\n",
    "# Generate synthetic data\n",
    "X, y = make_classification(n_samples=500, n_features=5, random_state=42)\n",
    "\n",
    "# Split data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train Logistic Regression model\n",
    "model = LogisticRegression(max_iter=5000)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Save the trained model\n",
    "joblib.dump(model, 'logistic_model.joblib')\n",
    "\n",
    "# Load the model\n",
    "loaded_model = joblib.load('logistic_model.joblib')\n",
    "\n",
    "# Make predictions with loaded model\n",
    "y_pred = loaded_model.predict(X_test)\n",
    "print(\"Predictions:\", y_pred)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d448a239-01bb-4b3a-916a-f1cb63b8b012",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
